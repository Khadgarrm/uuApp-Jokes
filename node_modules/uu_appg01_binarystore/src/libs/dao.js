const { DbConnection, UuDataStoreDao } = require("uu_appg01_datastore");

const Mongodb = require("mongodb");
const Crypto = require("crypto");
const StreamMeter = require("stream-meter");
const pump = require("pump");
const { Perflog } = require("uu_appg01_core-perflog");
const { Config } = require("uu_appg01_core-utils");

const DuplicateKey = require("./dao_errors/duplicate-key");
const UnexpectedError = require("./dao_errors/unexpected-error");
const InvalidRevision = require("./dao_errors/invalid-revision");
const MissingRevision = require("./dao_errors/missing-revision");
const NoiExceeded = require("./dao_errors/noi-exceeded");
const ObjectLocked = require("./dao_errors/object-locked");
const LockDoesNotExist = require("./dao_errors/lock-does-not-exist");
const ObjectNotFound = require("./dao_errors/object-not-found");
const SoiExceeded = require("./dao_errors/soi-exceeded");
const SobExceeded = require("./dao_errors/sob-exceeded");
const ExpiredLock = require("./dao_errors/expired-lock");
const BinaryStoreError = require("./dao_errors/binarystore-error");

const MAX_POOL_SIZE_CONFIG_PARAM = "uu_app_binarystore_max_pool_size";

class UuBinaryDao extends UuDataStoreDao {
  /**
   * constructor of the UuBinaryDao
   * @param name {string}
   * @param maxNoi {number}
   * @param maxSoi {number}
   * @param customUri {string}
   * @param maxSob {number}
   */

  constructor(name, maxNoi, maxSoi, customUri, maxSob) {
    const connectionOpts = {};
    const maxPoolSize = Config.getNumber(MAX_POOL_SIZE_CONFIG_PARAM);
    if (maxPoolSize) {
      connectionOpts.poolSize = maxPoolSize;
    }
    super(name, maxNoi, maxSoi, customUri, connectionOpts);
    this.maxSob = maxSob;
    this.Errors = {
      SoiExceeded,
      UnexpectedError,
      ObjectLocked,
      DuplicateKey,
      ObjectNotFound,
      LockDoesNotExist,
      ExpiredLock
    };
  }

  /**
   * insert data to database from stream
   * @async
   * @param uuBinary {object}
   * @param data {stream}
   * @param maxSob {number}
   * @returns {Promise.<void>}
   */
  async insertFromStream(uuBinary, data, maxSob = null) {
    uuBinary = { ...uuBinary };
    uuBinary = super._convertId(uuBinary);
    uuBinary["filename"] = uuBinary["filename"] || data["filename"] || "defaultName";
    uuBinary["contentType"] = uuBinary["contentType"] || data["contentType"] || "application/octet-stream";
    let maxSizeOfObject = maxSob || this.maxSob;
    await this._checkSoiAndNoi(uuBinary);

    let db = await DbConnection.get(this.customUri);
    let bucket = new Mongodb.GridFSBucket(db, { bucketName: this.collectionName });
    let streamMeter = StreamMeter(maxSizeOfObject);
    let writeStream = bucket.openUploadStream(uuBinary.filename, { contentType: uuBinary["contentType"] });

    let result = await this._streamInsert(data, streamMeter, writeStream, bucket, uuBinary);
    await super._recalculateCurrentNoiAfter(1, uuBinary["awid"]);

    return result;
  }

  /**
   * update data from stream
   * @async
   * @param filter {Object}
   * @param uuBinary {Object}
   * @param data {stream}
   * @param createVersion {boolean}
   * @param revisionStrategy {String}
   * @param lock {Lock}
   * @param maxSob {Number}
   * @returns {Promise<*>}
   */
  async updateFromStream(
    filter,
    uuBinary,
    data,
    createVersion = false,
    revisionStrategy = "REVISION",
    lock = null,
    maxSob = null
  ) {
    return await Perflog.measureSection(`${filter.awid}_UU_APP_BINARYSTORE_DAO_UPDATE_FROM_STREAM`, async () => {
      uuBinary = { ...uuBinary };
      filter = super._convertId(filter);
      let maxSizeOfObject = maxSob || this.maxSob;

      try {
        super._checkSoi(uuBinary);
      } catch (e) {
        throw new SoiExceeded(e);
      }

      let updateFilter = {
        $and: [filter]
      };

      let lockPart = this._getLockPart(lock);
      updateFilter["$and"].push(lockPart);

      let loadedUuBinary;
      await Perflog.measureSection(`${filter.awid}_UU_APP_BINARYSTORE_DAO_UPDATE_FROM_STREAM_GET_METADATA`, async () => {
        if (createVersion) {
          loadedUuBinary = await super.findOne(updateFilter, {}, { "sys.cts": -1 });
        } else {
          loadedUuBinary = await super.findOne(updateFilter);
        }
      })

      if (!loadedUuBinary) {
        let lockedObject = await super.findOne(filter);
        if (!lockedObject) {
          throw new ObjectNotFound();
        } else {
          throw new ObjectLocked();
        }
      }

      if (revisionStrategy === "REVISION") {
        if (!uuBinary.sys || uuBinary.sys.rev == null) {
          throw new MissingRevision();
        }
        if (loadedUuBinary.sys.rev !== uuBinary.sys.rev) {
          throw new InvalidRevision();
        }
      }

      let db, bucket;
      const perflogSectionName = `${filter.awid}_UU_APP_BINARYSTORE_DAO_UPDATE_FROM_STREAM_GET_CONNECTION`;
      await Perflog.measureSection(perflogSectionName, async (section) => {
        db = await DbConnection.get(this.customUri);
        bucket = new Mongodb.GridFSBucket(db, { bucketName: this.collectionName });
      })

      uuBinary["filename"] = uuBinary["filename"] || loadedUuBinary["filename"] || data["filename"] || "defaultName";
      uuBinary["contentType"] = uuBinary["contentType"] || data["contentType"] || "application/octet-stream";

      let writeStream = bucket.openUploadStream(uuBinary["filename"], { contentType: uuBinary["contentType"] });
      let streamMeter = StreamMeter(maxSizeOfObject);

      return await this._streamUpdate(
        db,
        data,
        streamMeter,
        writeStream,
        bucket,
        uuBinary,
        loadedUuBinary,
        createVersion
      );
    });
  }

  /**
   * stores new uuBinary in database
   * @async
   * @param uuBinary {object}
   * @returns {Promise.<TResult>} {object}
   */
  async insertOne(uuBinary) {
    uuBinary = { ...uuBinary };
    uuBinary = super._convertId(uuBinary);
    uuBinary["sys"] = super._createStamps();
    await this._checkSoiAndNoi(uuBinary);

    if (!uuBinary["code"]) {
      uuBinary["code"] = this._generateCode(32);
    }

    let db = await DbConnection.get(this.customUri);
    let response;
    try {
      response = await db.collection(this.collectionName).insertOne(uuBinary);
      response = response.ops[0];
    } catch (e) {
      if (e.message.match(/^E11000/)) {
        throw new DuplicateKey(e);
      } else {
        throw new UnexpectedError(e);
      }
    }

    if (uuBinary["awid"]) {
      super._recalculateCurrentNoiAfter(1, uuBinary["awid"]);
    }

    return response;
  }

  /**
   * return download stream on response
   * @async
   * @param filter {object} id or filename
   * @returns {Promise}
   */
  async openDownloadStream(filter) {
    return await Perflog.measureSection(`${filter.awid}_UU_APP_BINARYSTORE_DAO_OPEN_DOWNLOAD_STREAM`, async () => {
      filter = { ...filter };
      filter = super._convertId(filter);

      let db, bucket;
      const perflogSectionName = `${filter.awid}_UU_APP_BINARYSTORE_DAO_OPEN_DOWNLOAD_STREAM_GET_CONNECTION`;
      await Perflog.measureSection(perflogSectionName, async (section) => {
        db = await DbConnection.get(this.customUri);
        bucket = new Mongodb.GridFSBucket(db, { bucketName: this.collectionName });

        if (Perflog._isTraceable(perflogSectionName)) {
          try {
            const dbClient = await DbConnection.getDbClient(this.customUri);
            section.setAttribute("dbClientOptions", JSON.stringify(dbClient.s.options));
          } catch (e) {
            section.setAttribute("dbClientOptions", "Failed to load:" + JSON.stringify(e));
          }
        }
      });

      let document = await Perflog.measureSection(`${filter.awid}_UU_APP_BINARYSTORE_DAO_OPEN_DOWNLOAD_STREAM_METADATA`, async () => {
        return super.findOne(filter, {}, { "sys.cts": -1 });
      });

      let documentFilter = {};
      if (!document) {
        throw new ObjectNotFound();
      } else {
        let fileId = document["fileId"];
        if (!fileId && document["fid"]) fileId = Mongodb.ObjectID(document["fid"]);

        documentFilter["_id"] = fileId;
        let metadata = await db.collection(`${this.collectionName}.files`).findOne(documentFilter);
        return new Promise(async (resolve, reject) => {
          let readStream = bucket.openDownloadStream(documentFilter["_id"]);

          readStream.on("error", e => {
            if (e.code === "ENOENT") {
              return reject(new ObjectNotFound(e));
            }
            reject(new UnexpectedError(e));
          });

          let contentType = document.contentType || metadata.contentType;
          if (contentType === "binary/octet-stream") {
            contentType = "application/octet-stream";
          }

          resolve({
            contentLength: metadata.length,
            contentType,
            filename: document.filename || metadata.filename,
            checksum: metadata.md5,
            stream: readStream
          });
        });
      }
    })
  }

  /**
   * delete object from database
   * @async
   * @param filter {object}
   * @param lock {Lock}
   * @returns {Promise.<TResult>}
   */
  async deleteOne(filter, lock = null) {
    filter = super._convertId(filter);

    let deleteFilter = {
      $and: [filter]
    };
    let lockPart = this._getLockPart(lock);

    deleteFilter["$and"].push(lockPart);

    let db = await DbConnection.get(this.customUri);
    let bucket = new Mongodb.GridFSBucket(db, { bucketName: this.collectionName });

    let objectToDelete = await super.findOne(deleteFilter);
    if (objectToDelete) {
      let fileId = objectToDelete["fileId"];
      if (!fileId && objectToDelete["fid"]) fileId = Mongodb.ObjectID(objectToDelete["fid"]);

      try {
        await db.collection(this.collectionName).deleteOne(deleteFilter);
        await bucket.delete(fileId);
      } catch (e) {
        throw new UnexpectedError(e);
      }
    } else {
      let lockedObject = await super.findOne(filter);
      if (lockedObject) {
        throw new ObjectLocked();
      } else {
        throw new ObjectNotFound();
      }
    }
  }

  /**
   * find one object and update it
   * @async
   * @param filter {object}
   * @param uuBinary {object}
   * @param createVersion {boolean}
   * @param revisionStrategy {String}
   * @param lock {Lock}
   * @returns {Promise.<TResult>} return updated object
   */
  async findOneAndUpdate(filter, uuBinary, createVersion = false, revisionStrategy = "REVISION", lock = null) {
    uuBinary = { ...uuBinary };
    filter = super._convertId(filter);
    super._checkSoi(uuBinary);

    let updateFilter = {
      $and: [filter]
    };
    let lockPart = this._getLockPart(lock);
    updateFilter["$and"].push(lockPart);
    let db = await DbConnection.get(this.customUri);

    let loadedUuBinary;
    if (createVersion) {
      loadedUuBinary = await super.findOne(filter, {}, { "sys.cts": -1 });
      if (!loadedUuBinary) {
        throw new ObjectNotFound();
      }
    }

    if (revisionStrategy === "REVISION") {
      if (uuBinary.sys == null || uuBinary.sys.rev == null) {
        throw new MissingRevision();
      }
      if (createVersion && loadedUuBinary.sys.rev !== uuBinary.sys.rev) {
        throw new InvalidRevision();
      }
    }

    if (createVersion) {
      return await this._createVersion(db, uuBinary, loadedUuBinary);
    } else {
      if (revisionStrategy === "REVISION") {
        let revisionPart = {
          "sys.rev": uuBinary.sys.rev
        };
        updateFilter["$and"].push(revisionPart);
      }

      return await this._updateObject(db, uuBinary, updateFilter, filter, revisionStrategy);
    }
  }

  _prepareUpdate(update) {
    delete update["sys"];

    let preparedUpdate = {};
    for (let k in update) {
      if (update.hasOwnProperty(k) && k.startsWith("$")) {
        preparedUpdate[k] = update[k];
        delete update[k];
      }
    }

    // merge inc with increment of revision, if is contained in update query
    if (!preparedUpdate["$inc"]) {
      preparedUpdate["$inc"] = {};
    }
    preparedUpdate["$inc"]["sys.rev"] = 1;

    if (preparedUpdate.hasOwnProperty("$set")) {
      preparedUpdate["$set"] = { ...preparedUpdate["$set"], ...update };
    } else if (Object.keys(update).length > 0) {
      preparedUpdate["$set"] = update;
    } else {
      preparedUpdate["$set"] = {};
    }
    preparedUpdate["$set"]["sys.mts"] = new Date();

    return preparedUpdate;
  }

  _generateCode(n = 32) {
    if (n <= 0) {
      return "";
    }
    var rs = "";
    try {
      rs = Crypto.randomBytes(Math.ceil(n / 2))
        .toString("hex")
        .slice(0, n);
      /* note: could do this non-blocking, but still might fail */
    } catch (ex) {
      /* known exception cause: depletion of entropy info for randomBytes */
      /* weaker random fallback */
      rs = "";
      var r = n % 8,
        q = (n - r) / 8,
        i;
      for (i = 0; i < q; i++) {
        rs += Math.random()
          .toString(16)
          .slice(2);
      }
      if (r > 0) {
        rs += Math.random()
          .toString(16)
          .slice(2, i);
      }
    }
    return rs;
  }

  async _deleteCorruptedChunks(bucket, id, alreadyDeleted) {
    if (!alreadyDeleted) {
      try {
        await bucket.delete(id);
      } catch (e) {
        //already deleted or process failed during first chunk
      }
    }
    return true;
  }

  _getLockPart(lock) {
    let lockPart;
    if (lock) {
      lockPart = {
        "sys.lockHash": lock.hash,
        "sys.lockExpTs": {
          $gt: new Date()
        }
      };
    } else {
      lockPart = {
        $or: [
          {
            "sys.lockHash": {
              $exists: false
            }
          },
          {
            "sys.lockHash": {
              $exists: true
            },
            "sys.lockExpTs": {
              $lt: new Date()
            }
          }
        ]
      };
    }

    return lockPart;
  }

  async _streamInsert(data, streamMeter, writeStream, bucket, uuBinary) {
    return new Promise((resolve, reject) => {
      pump(data, streamMeter, writeStream);
      let fileId = writeStream["id"];
      let streamMeterTriggedError = null;
      let alreadyDeleted = false;

      streamMeter.on("error", async e => {
        streamMeterTriggedError = e;
      });

      data.on("error", async e => {
        alreadyDeleted = await this._deleteCorruptedChunks(bucket, fileId, alreadyDeleted);
        return reject(new UnexpectedError(e));
      });

      writeStream
        .on("error", async e => {
          alreadyDeleted = await this._deleteCorruptedChunks(bucket, fileId, alreadyDeleted);
          if (streamMeterTriggedError) {
            return reject(new SobExceeded(streamMeterTriggedError));
          } else {
            return reject(new UnexpectedError(e));
          }
        })
        .on("finish", async file => {
          uuBinary["fileId"] = file["_id"];

          if (!uuBinary["code"]) {
            uuBinary["code"] = this._generateCode(32);
          }

          try {
            let res = await this.insertOne(uuBinary);
            resolve(super._convertToId(res));
          } catch (e) {
            reject(e);
          }
        });
    });
  }

  async _streamUpdate(db, data, streamMeter, writeStream, bucket, uuBinary, loadedUuBinary, createVersion) {
    return new Promise((resolve, reject) => {

      pump(data, streamMeter, writeStream);
      let fileId = writeStream["id"];
      let streamMeterTriggedError = null;
      let alreadyDeleted = false;

      let query = {
        _id: loadedUuBinary["id"]
      };

      streamMeter.on("error", e => {
        streamMeterTriggedError = e;
      });

      data.on("error", async e => {
        alreadyDeleted = await this._deleteCorruptedChunks(bucket, fileId, alreadyDeleted);
        return reject(new UnexpectedError(e));
      });

      writeStream
        .on("error", async e => {
          alreadyDeleted = await this._deleteCorruptedChunks(bucket, fileId, alreadyDeleted);
          if (streamMeterTriggedError) {
            return reject(new SobExceeded(streamMeterTriggedError));
          } else {
            return reject(new UnexpectedError(e));
          }
        })
        .on("finish", async file => {
          let update = {
            $set: {}
          };
          delete uuBinary["sys"];
          let fileIdOrFid = loadedUuBinary["fileId"] ? "fileId" : "fid";

          let set = {};
          set = { ...set, ...uuBinary };
          set["filename"] = uuBinary["filename"];
          set["contentType"] = uuBinary["contentType"] || file["contentType"];
          set[fileIdOrFid] = fileIdOrFid === "fid" ? file["_id"].toString() : file["_id"];
          set["sys.mts"] = new Date();
          update["$inc"] = {
            "sys.rev": 1
          };
          update["$set"] = set;

          let responseObject;
          try {
            await Perflog.measureSection(`${loadedUuBinary.awid}_UU_APP_BINARYSTORE_DAO_UPDATE_FROM_STREAM_UU_BINARY`, async () => {
              let newObject = { ...loadedUuBinary, ...uuBinary };
              if (createVersion) {
                newObject["sys"]["cts"] = new Date();
                newObject["sys"]["mts"] = new Date();
                newObject[fileIdOrFid] = fileIdOrFid === "fid" ? file["_id"].toString() : file["_id"];
                newObject["contentType"] = uuBinary["contentType"] || file["contentType"];
                delete newObject["id"];

                responseObject = await db.collection(this.collectionName).insertOne(newObject);
                responseObject = responseObject.ops[0];
              } else {
                responseObject = await db
                  .collection(this.collectionName)
                  .findOneAndUpdate(query, update, { returnDocument: "after" });
                responseObject = responseObject.value;
                let fileIdAsObject =
                  typeof loadedUuBinary[fileIdOrFid] === "string"
                    ? Mongodb.ObjectID(loadedUuBinary["fid"])
                    : loadedUuBinary[fileIdOrFid];
                await bucket.delete(fileIdAsObject);
              }
            })
          } catch (e) {
            await this._deleteCorruptedChunks(bucket, file["_id"]);
            reject(new UnexpectedError(e));
          }

          delete responseObject[fileIdOrFid];
          resolve(super._convertToId(responseObject));
        });
    });
  }

  async _checkSoiAndNoi(uuBinary) {
    try {
      super._checkSoi(uuBinary);
    } catch (e) {
      throw new SoiExceeded(e);
    }

    if (uuBinary["awid"]) {
      let correctNoi = await super._checkCurrentNoiBefore(1, uuBinary["awid"]);
      if (correctNoi !== true) {
        throw new NoiExceeded();
      }
    }
  }

  async _createVersion(db, uuBinary, loadedUuBinary) {
    let update = { ...uuBinary };
    delete update["sys"];
    loadedUuBinary = { ...loadedUuBinary, ...update };

    delete loadedUuBinary["_id"];
    delete loadedUuBinary["id"];

    if (loadedUuBinary["sys"] == null) {
      loadedUuBinary["sys"] = {};
    }
    loadedUuBinary["sys"]["mts"] = new Date();
    loadedUuBinary["sys"]["cts"] = new Date();

    let response;
    try {
      response = await db.collection(this.collectionName).insertOne(loadedUuBinary);
      response = response.ops[0];
    } catch (e) {
      if (e.message.match(/^E11000/)) {
        throw new DuplicateKey(e);
      } else {
        throw new UnexpectedError(e);
      }
    }
    return super._convertToId(response);
  }

  async _updateObject(db, uuBinary, updateFilter, filter, revisionStrategy) {
    let update = this._prepareUpdate({ ...uuBinary });

    return await db
      .collection(this.collectionName)
      .findOneAndUpdate(updateFilter, update, { returnDocument: "after" })
      .then(result => {
        if (result.value) {
          return super._convertToId(result.value);
        } else {
          return super._findWrapper(filter).then(res => {
            if (!res || res.length === 0) {
              throw new ObjectNotFound();
            } else if (revisionStrategy === "REVISION" && res[0].sys.rev !== uuBinary.sys.rev) {
              throw new InvalidRevision();
            } else if (res[0]["sys"] && res[0]["sys"]["lockHash"]) {
              throw new ObjectLocked();
            } else {
              throw new UnexpectedError();
            }
          });
        }
      })
      .catch(e => {
        if (e.message.match(/^E1100[01]/)) {
          throw new DuplicateKey();
        } else if (e instanceof BinaryStoreError) {
          throw e;
        } else {
          throw new UnexpectedError(e);
        }
      });
  }

}

module.exports = UuBinaryDao;
